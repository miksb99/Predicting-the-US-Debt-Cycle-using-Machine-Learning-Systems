{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93cd37ff-a8ad-463b-8556-a33b2f3a8289",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T01:32:50.643995Z",
     "iopub.status.busy": "2025-11-20T01:32:50.643532Z",
     "iopub.status.idle": "2025-11-20T01:32:50.996378Z",
     "shell.execute_reply": "2025-11-20T01:32:50.995576Z",
     "shell.execute_reply.started": "2025-11-20T01:32:50.643976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 610\n",
      "Validation rows: 396\n",
      "\n",
      "=== Validation performance (ValidationML.csv) ===\n",
      "AUC   : 0.758146\n",
      "Brier : 0.105898\n",
      "\n",
      "Saved validation probabilities to 'ValidationML_with_probs.csv'.\n",
      "Column added: 'Depression_prob' (predicted probability of Depression = 1).\n"
     ]
    }
   ],
   "source": [
    "# Depression Predictor, Validation test to identify optimal hyper-parameters (Gamma, Dim, & Lambda)\n",
    "# Data used based from https://www.globalmacrodata.com/\n",
    "# train_validate_depression_rff.py\n",
    "# Train on TrainML.csv, validate on ValidationML.csv.\n",
    "# Model: Standardize -> RFF (RBF) -> Logistic Regression (L2 / ridge-like)\n",
    "# Target: binary column \"Depression\"\n",
    "# Outputs: AUC, Brier, and probabilities for ValidationML rows.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "# ---------- Config ----------\n",
    "TRAIN_CSV = \"TestTrainML2.csv\"\n",
    "VAL_CSV   = \"TestValidation2.csv\"\n",
    "\n",
    "RFF_GAMMA = 0.15      # RBF width\n",
    "RFF_DIM   = 4000     # number of random Fourier features\n",
    "LOGIT_C   = 20.0     # inverse of L2 strength\n",
    "SEED      = 42\n",
    "\n",
    "LABEL_COL = \"Depression\"  # binary outcome\n",
    "\n",
    "# Features (same as before, but WITHOUT \"Cons/GDP\")\n",
    "FEATURES = [\n",
    "    # Circulation\n",
    "    \"M0/GDP\",\"M1/GDP\",\"M0/M1\",\n",
    "    # Creation\n",
    "    \"∆ Debt/GDP\",\"Debt Growth\",\"Invest/GDP\",\n",
    "    # Valuation\n",
    "    \"REER\",\"Inflation Rate\",\"ST Interest\",\"HPI\",\"Curve\",\n",
    "    # Efficiency\n",
    "    \"UR\",\"CreditSprd\",\"Nom GDPg\"\n",
    "]\n",
    "\n",
    "# Output CSV for validation predictions\n",
    "OUT_CSV = \"ValidationML_with_probs.csv\"\n",
    "\n",
    "# ---------- Load ----------\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df   = pd.read_csv(VAL_CSV)\n",
    "\n",
    "# Drop rows with missing features or label\n",
    "train_df = train_df.dropna(subset=FEATURES + [LABEL_COL]).copy()\n",
    "val_df   = val_df.dropna(subset=FEATURES + [LABEL_COL]).copy()\n",
    "\n",
    "X_tr = train_df[FEATURES].values\n",
    "y_tr = train_df[LABEL_COL].astype(int).values\n",
    "\n",
    "X_va = val_df[FEATURES].values\n",
    "y_va = val_df[LABEL_COL].astype(int).values\n",
    "\n",
    "print(f\"Train rows: {X_tr.shape[0]}\")\n",
    "print(f\"Validation rows: {X_va.shape[0]}\")\n",
    "\n",
    "# ---------- Standardize -> RFF -> Logistic ----------\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "Ztr    = scaler.transform(X_tr)\n",
    "\n",
    "rff = RBFSampler(\n",
    "    gamma=RFF_GAMMA,\n",
    "    n_components=RFF_DIM,\n",
    "    random_state=SEED\n",
    ").fit(Ztr)\n",
    "\n",
    "Ztr_r = rff.transform(Ztr)\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    C=LOGIT_C,\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=SEED\n",
    ").fit(Ztr_r, y_tr)\n",
    "\n",
    "# ---------- Validate (AUC + Brier on PROBABILITIES) ----------\n",
    "Zva   = scaler.transform(X_va)\n",
    "Zva_r = rff.transform(Zva)\n",
    "p_va  = clf.predict_proba(Zva_r)[:, 1]  # probability Depression = 1\n",
    "\n",
    "auc   = roc_auc_score(y_va, p_va)\n",
    "brier = brier_score_loss(y_va, p_va)\n",
    "\n",
    "print(\"\\n=== Validation performance (ValidationML.csv) ===\")\n",
    "print(f\"AUC   : {auc:.6f}\")\n",
    "print(f\"Brier : {brier:.6f}\")\n",
    "\n",
    "# ---------- Save validation probabilities ----------\n",
    "val_out = val_df.copy()\n",
    "val_out[\"Depression_prob\"] = p_va\n",
    "\n",
    "val_out.to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nSaved validation probabilities to '{OUT_CSV}'.\")\n",
    "print(\"Column added: 'Depression_prob' (predicted probability of Depression = 1).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60a921d-a1c7-4351-8b21-4a07dd4f28f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:34:16.331194Z",
     "iopub.status.busy": "2025-11-20T00:34:16.330693Z",
     "iopub.status.idle": "2025-11-20T00:34:17.011315Z",
     "shell.execute_reply": "2025-11-20T00:34:16.995818Z",
     "shell.execute_reply.started": "2025-11-20T00:34:16.331159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 1037\n",
      "Validation rows: 60\n",
      "\n",
      "=== Validation performance (ValidationML.csv) ===\n",
      "AUC   : 0.915254\n",
      "Brier : 0.085230\n",
      "\n",
      "Saved validation probabilities to 'CheckML_with_probs.csv'.\n",
      "Column added: 'Depression_prob' (predicted probability of Depression = 1).\n"
     ]
    }
   ],
   "source": [
    "# train_predict_depression_rff.py\n",
    "# Train on Train2ML.csv, validate on PredictML.csv.\n",
    "# Model: Standardize -> RFF (RBF) -> Logistic Regression (L2 / ridge-like)\n",
    "# Target: binary column \"Depression\"\n",
    "# Outputs: AUC, Brier, and probabilities for ValidationML rows.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "# ---------- Config ----------\n",
    "TRAIN_CSV = \"Train2ML.csv\"\n",
    "VAL_CSV   = \"PredictML2.csv\"\n",
    "\n",
    "RFF_GAMMA = 0.2      # RBF width\n",
    "RFF_DIM   = 3000     # number of random Fourier features\n",
    "LOGIT_C   = 20.0     # inverse of L2 strength\n",
    "SEED      = 42\n",
    "\n",
    "LABEL_COL = \"Depression\"  # binary outcome\n",
    "\n",
    "# Features (same as before, but WITHOUT \"Cons/GDP\")\n",
    "FEATURES = [\n",
    "    # Circulation\n",
    "    \"M0/GDP\",\"M1/GDP\",\"M0/M1\",\n",
    "    # Creation\n",
    "    \"∆ Debt/GDP\",\"Debt Growth\",\"Invest/GDP\",\n",
    "    # Valuation\n",
    "    \"REER\",\"Inflation Rate\",\"ST Interest\",\"HPI\",\"Curve\",\n",
    "    # Efficiency\n",
    "    \"UR\",\"CreditSprd\",\"Nom GDPg\"\n",
    "]\n",
    "\n",
    "# Output CSV for validation predictions\n",
    "OUT_CSV = \"CheckML_with_probs.csv\"\n",
    "\n",
    "# ---------- Load ----------\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df   = pd.read_csv(VAL_CSV)\n",
    "\n",
    "# Drop rows with missing features or label\n",
    "train_df = train_df.dropna(subset=FEATURES + [LABEL_COL]).copy()\n",
    "val_df   = val_df.dropna(subset=FEATURES + [LABEL_COL]).copy()\n",
    "\n",
    "X_tr = train_df[FEATURES].values\n",
    "y_tr = train_df[LABEL_COL].astype(int).values\n",
    "\n",
    "X_va = val_df[FEATURES].values\n",
    "y_va = val_df[LABEL_COL].astype(int).values\n",
    "\n",
    "print(f\"Train rows: {X_tr.shape[0]}\")\n",
    "print(f\"Validation rows: {X_va.shape[0]}\")\n",
    "\n",
    "# ---------- Standardize -> RFF -> Logistic ----------\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "Ztr    = scaler.transform(X_tr)\n",
    "\n",
    "rff = RBFSampler(\n",
    "    gamma=RFF_GAMMA,\n",
    "    n_components=RFF_DIM,\n",
    "    random_state=SEED\n",
    ").fit(Ztr)\n",
    "\n",
    "Ztr_r = rff.transform(Ztr)\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    C=LOGIT_C,\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=SEED\n",
    ").fit(Ztr_r, y_tr)\n",
    "\n",
    "# ---------- Validate (AUC + Brier on PROBABILITIES) ----------\n",
    "Zva   = scaler.transform(X_va)\n",
    "Zva_r = rff.transform(Zva)\n",
    "p_va  = clf.predict_proba(Zva_r)[:, 1]  # probability Depression = 1\n",
    "\n",
    "auc   = roc_auc_score(y_va, p_va)\n",
    "brier = brier_score_loss(y_va, p_va)\n",
    "\n",
    "print(\"\\n=== Validation performance (ValidationML.csv) ===\")\n",
    "print(f\"AUC   : {auc:.6f}\")\n",
    "print(f\"Brier : {brier:.6f}\")\n",
    "\n",
    "# ---------- Save validation probabilities ----------\n",
    "val_out = val_df.copy()\n",
    "val_out[\"Depression_prob\"] = p_va\n",
    "\n",
    "val_out.to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nSaved validation probabilities to '{OUT_CSV}'.\")\n",
    "print(\"Column added: 'Depression_prob' (predicted probability of Depression = 1).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe2527a-7326-4af5-a2cb-e1507e6d2fab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:36:20.638929Z",
     "iopub.status.busy": "2025-11-20T00:36:20.638564Z",
     "iopub.status.idle": "2025-11-20T00:36:20.949760Z",
     "shell.execute_reply": "2025-11-20T00:36:20.948354Z",
     "shell.execute_reply.started": "2025-11-20T00:36:20.638906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 1037\n",
      "Forecast rows (2025 features -> 2026 prob): 25\n",
      "\n",
      "Saved probabilities to 'ForecastML3_with_probs.csv' (column: Depression_prob_2026).\n"
     ]
    }
   ],
   "source": [
    "# train_predict_depression_rff.py\n",
    "# Train on Train2ML.csv, score ForecastML.csv as 2026 probabilities (from 2025 features).\n",
    "# Model: Standardize -> RFF (RBF) -> Logistic Regression (L2)\n",
    "# Target column: \"Depression\" (binary) in TRAIN only. We do not evaluate on Forecast.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ---------- Config ----------\n",
    "TRAIN_CSV = \"Train2ML.csv\"\n",
    "VAL_CSV   = \"ForecastML3.csv\"       # 2025 rows; we will predict 2026 probs\n",
    "\n",
    "RFF_GAMMA = 0.2      # RBF width\n",
    "RFF_DIM   = 3000     # number of random Fourier features\n",
    "LOGIT_C   = 20.0     # inverse of L2 strength (larger C = weaker L2)\n",
    "SEED      = 42\n",
    "\n",
    "LABEL_COL = \"Depression\"  # binary outcome in TRAIN\n",
    "\n",
    "# Features (same as before, without \"Cons/GDP\")\n",
    "FEATURES = [\n",
    "    # Circulation\n",
    "    \"M0/GDP\",\"M1/GDP\",\"M0/M1\",\n",
    "    # Creation\n",
    "    \"∆ Debt/GDP\",\"Debt Growth\",\"Invest/GDP\",\n",
    "    # Valuation\n",
    "    \"REER\",\"Inflation Rate\",\"ST Interest\",\"HPI\",\"Curve\",\n",
    "    # Efficiency\n",
    "    \"UR\",\"CreditSprd\",\"Nom GDPg\"\n",
    "]\n",
    "\n",
    "OUT_CSV = \"ForecastML3_with_probs.csv\"\n",
    "\n",
    "# ---------- Load ----------\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df   = pd.read_csv(VAL_CSV)\n",
    "\n",
    "# Drop rows with missing features/label in TRAIN; drop missing features in FORECAST\n",
    "train_df = train_df.dropna(subset=FEATURES + [LABEL_COL]).copy()\n",
    "val_df   = val_df.dropna(subset=FEATURES).copy()\n",
    "\n",
    "# Matrices\n",
    "X_tr = train_df[FEATURES].values\n",
    "y_tr = train_df[LABEL_COL].astype(int).values\n",
    "\n",
    "X_va = val_df[FEATURES].values\n",
    "\n",
    "print(f\"Train rows: {X_tr.shape[0]}\")\n",
    "print(f\"Forecast rows (2025 features -> 2026 prob): {X_va.shape[0]}\")\n",
    "\n",
    "# ---------- Standardize -> RFF -> Logistic ----------\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "Ztr    = scaler.transform(X_tr)\n",
    "\n",
    "rff = RBFSampler(\n",
    "    gamma=RFF_GAMMA,\n",
    "    n_components=RFF_DIM,\n",
    "    random_state=SEED\n",
    ").fit(Ztr)\n",
    "\n",
    "Ztr_r = rff.transform(Ztr)\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    C=LOGIT_C,\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=SEED\n",
    ").fit(Ztr_r, y_tr)\n",
    "\n",
    "# ---------- Predict Forecast (as 2026 probability) ----------\n",
    "Zva   = scaler.transform(X_va)\n",
    "Zva_r = rff.transform(Zva)\n",
    "p_va  = clf.predict_proba(Zva_r)[:, 1]  # probability Depression=1 (for 2026)\n",
    "\n",
    "# ---------- Save ----------\n",
    "val_out = val_df.copy()\n",
    "val_out[\"Depression_prob_2026\"] = p_va\n",
    "\n",
    "val_out.to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nSaved probabilities to '{OUT_CSV}' (column: Depression_prob_2026).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "129b1726-9912-45e7-8c04-24c76e319fd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T01:21:32.143177Z",
     "iopub.status.busy": "2025-11-20T01:21:32.142809Z",
     "iopub.status.idle": "2025-11-20T01:21:32.656217Z",
     "shell.execute_reply": "2025-11-20T01:21:32.655201Z",
     "shell.execute_reply.started": "2025-11-20T01:21:32.143151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows (with next-year labels): 610\n",
      "Validation rows (with next-year labels): 396\n",
      "\n",
      "=== Validation performance (predicting next-year Depression) ===\n",
      "AUC   : 0.719733\n",
      "Brier : 0.107820\n",
      "\n",
      "Saved validation probabilities to 'ValidationML_with_probs.csv'.\n",
      "Column added: 'Depression_prob_next' (P(Depression in next year = 1)).\n"
     ]
    }
   ],
   "source": [
    "# Depression Predictor, Validation test to identify optimal hyper-parameters (Gamma, Dim, & Lambda)\n",
    "# Train on TrainML.csv, validate on ValidationML.csv.\n",
    "# Model: Standardize -> RFF (RBF) -> Logistic Regression (L2 / ridge-like)\n",
    "# Target: Depression in year t+1 (Depression_next) using features at time t.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "# ---------- Config ----------\n",
    "TRAIN_CSV = \"TrainML.csv\"\n",
    "VAL_CSV   = \"ValidationML.csv\"\n",
    "\n",
    "RFF_GAMMA = 0.15      # RBF width\n",
    "RFF_DIM   = 3000     # number of random Fourier features\n",
    "LOGIT_C   = 20.0     # inverse of L2 strength\n",
    "SEED      = 42\n",
    "\n",
    "LABEL_COL = \"Depression_next\"  # binary outcome: Depression in year t+1\n",
    "\n",
    "# Features (same as before, but WITHOUT \"Cons/GDP\")\n",
    "FEATURES = [\n",
    "    # Circulation\n",
    "    \"M0/GDP\",\"M1/GDP\",\"M0/M1\",\n",
    "    # Creation\n",
    "    \"∆ Debt/GDP\",\"Debt Growth\",\"Invest/GDP\",\n",
    "    # Valuation\n",
    "    \"REER\",\"Inflation Rate\",\"ST Interest\",\"HPI\",\"Curve\",\n",
    "    # Efficiency\n",
    "    \"UR\",\"CreditSprd\",\"Nom GDPg\"\n",
    "]\n",
    "\n",
    "# Output CSV for validation predictions\n",
    "OUT_CSV = \"ValidationML_with_probs.csv\"\n",
    "\n",
    "# ---------- Load ----------\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df   = pd.read_csv(VAL_CSV)\n",
    "\n",
    "# ---------- Build next-year labels (Depression_{t+1}) ----------\n",
    "# Sort by Country & Year so shift(-1) means \"next year within same country\"\n",
    "train_df = train_df.sort_values([\"Country\", \"Year\"])\n",
    "val_df   = val_df.sort_values([\"Country\", \"Year\"])\n",
    "\n",
    "# For each country, label for year t is Depression in year t+1\n",
    "train_df[LABEL_COL] = train_df.groupby(\"Country\")[\"Depression\"].shift(-1)\n",
    "val_df[LABEL_COL]   = val_df.groupby(\"Country\")[\"Depression\"].shift(-1)\n",
    "\n",
    "# Drop rows where we don't have full features or next-year label\n",
    "train_df = train_df.dropna(subset=FEATURES + [LABEL_COL]).copy()\n",
    "val_df   = val_df.dropna(subset=FEATURES + [LABEL_COL]).copy()\n",
    "\n",
    "X_tr = train_df[FEATURES].values\n",
    "y_tr = train_df[LABEL_COL].astype(int).values\n",
    "\n",
    "X_va = val_df[FEATURES].values\n",
    "y_va = val_df[LABEL_COL].astype(int).values\n",
    "\n",
    "print(f\"Train rows (with next-year labels): {X_tr.shape[0]}\")\n",
    "print(f\"Validation rows (with next-year labels): {X_va.shape[0]}\")\n",
    "\n",
    "# ---------- Standardize -> RFF -> Logistic ----------\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "Ztr    = scaler.transform(X_tr)\n",
    "\n",
    "rff = RBFSampler(\n",
    "    gamma=RFF_GAMMA,\n",
    "    n_components=RFF_DIM,\n",
    "    random_state=SEED\n",
    ").fit(Ztr)\n",
    "\n",
    "Ztr_r = rff.transform(Ztr)\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    C=LOGIT_C,\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=SEED\n",
    ").fit(Ztr_r, y_tr)\n",
    "\n",
    "# ---------- Validate (AUC + Brier on PROBABILITIES for Depression_{t+1}) ----------\n",
    "Zva   = scaler.transform(X_va)\n",
    "Zva_r = rff.transform(Zva)\n",
    "p_va  = clf.predict_proba(Zva_r)[:, 1]  # P(Depression_next = 1)\n",
    "\n",
    "auc   = roc_auc_score(y_va, p_va)\n",
    "brier = brier_score_loss(y_va, p_va)\n",
    "\n",
    "print(\"\\n=== Validation performance (predicting next-year Depression) ===\")\n",
    "print(f\"AUC   : {auc:.6f}\")\n",
    "print(f\"Brier : {brier:.6f}\")\n",
    "\n",
    "# ---------- Save validation probabilities ----------\n",
    "val_out = val_df.copy()\n",
    "# This is: P(Depression in Year+1 | features at Year)\n",
    "val_out[\"Depression_prob_next\"] = p_va\n",
    "\n",
    "val_out.to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nSaved validation probabilities to '{OUT_CSV}'.\")\n",
    "print(\"Column added: 'Depression_prob_next' (P(Depression in next year = 1)).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "868990c0-0883-434a-a55d-2c01b27ff5e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T01:42:10.767565Z",
     "iopub.status.busy": "2025-11-20T01:42:10.767055Z",
     "iopub.status.idle": "2025-11-20T01:42:11.411907Z",
     "shell.execute_reply": "2025-11-20T01:42:11.410313Z",
     "shell.execute_reply.started": "2025-11-20T01:42:10.767542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows (with next-year labels): 1021\n",
      "Validation rows (with next-year labels): 53\n",
      "\n",
      "=== Validation performance (predicting next-year Depression) ===\n",
      "AUC   : 0.750000\n",
      "Brier : 0.115521\n",
      "\n",
      "Saved validation probabilities to 'ValidationML_with_probs.csv'.\n",
      "Column added: 'Depression_prob_next' (P(Depression in next year = 1)).\n"
     ]
    }
   ],
   "source": [
    "# Depression Predictor, Validation test to identify optimal hyper-parameters (Gamma, Dim, & Lambda)\n",
    "# Train on TrainML.csv, validate on ValidationML.csv.\n",
    "# Model: Standardize -> RFF (RBF) -> Logistic Regression (L2 / ridge-like)\n",
    "# Target: Depression in year t+1 (Depression_next) using features at time t.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "# ---------- Config ----------\n",
    "TRAIN_CSV = \"Train2ML.csv\"\n",
    "VAL_CSV   = \"PredictML2.csv\"\n",
    "\n",
    "RFF_GAMMA = 0.15      # RBF width\n",
    "RFF_DIM   = 3000     # number of random Fourier features\n",
    "LOGIT_C   = 20.0     # inverse of L2 strength\n",
    "SEED      = 42\n",
    "\n",
    "LABEL_COL = \"Depression_next\"  # binary outcome: Depression in year t+1\n",
    "\n",
    "# Features (same as before, but WITHOUT \"Cons/GDP\")\n",
    "FEATURES = [\n",
    "    # Circulation\n",
    "    \"M0/GDP\",\"M1/GDP\",\"M0/M1\",\n",
    "    # Creation\n",
    "    \"∆ Debt/GDP\",\"Debt Growth\",\"Invest/GDP\",\n",
    "    # Valuation\n",
    "    \"REER\",\"Inflation Rate\",\"ST Interest\",\"HPI\",\"Curve\",\n",
    "    # Efficiency\n",
    "    \"UR\",\"CreditSprd\",\"Nom GDPg\"\n",
    "]\n",
    "\n",
    "# Output CSV for validation predictions\n",
    "OUT_CSV = \"ValidationML_with_probs.csv\"\n",
    "\n",
    "# ---------- Load ----------\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df   = pd.read_csv(VAL_CSV)\n",
    "\n",
    "# ---------- Build next-year labels (Depression_{t+1}) ----------\n",
    "# Sort by Country & Year so shift(-1) means \"next year within same country\"\n",
    "train_df = train_df.sort_values([\"Country\", \"Year\"])\n",
    "val_df   = val_df.sort_values([\"Country\", \"Year\"])\n",
    "\n",
    "# For each country, label for year t is Depression in year t+1\n",
    "train_df[LABEL_COL] = train_df.groupby(\"Country\")[\"Depression\"].shift(-1)\n",
    "val_df[LABEL_COL]   = val_df.groupby(\"Country\")[\"Depression\"].shift(-1)\n",
    "\n",
    "# Drop rows where we don't have full features or next-year label\n",
    "train_df = train_df.dropna(subset=FEATURES + [LABEL_COL]).copy()\n",
    "val_df   = val_df.dropna(subset=FEATURES + [LABEL_COL]).copy()\n",
    "\n",
    "X_tr = train_df[FEATURES].values\n",
    "y_tr = train_df[LABEL_COL].astype(int).values\n",
    "\n",
    "X_va = val_df[FEATURES].values\n",
    "y_va = val_df[LABEL_COL].astype(int).values\n",
    "\n",
    "print(f\"Train rows (with next-year labels): {X_tr.shape[0]}\")\n",
    "print(f\"Validation rows (with next-year labels): {X_va.shape[0]}\")\n",
    "\n",
    "# ---------- Standardize -> RFF -> Logistic ----------\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "Ztr    = scaler.transform(X_tr)\n",
    "\n",
    "rff = RBFSampler(\n",
    "    gamma=RFF_GAMMA,\n",
    "    n_components=RFF_DIM,\n",
    "    random_state=SEED\n",
    ").fit(Ztr)\n",
    "\n",
    "Ztr_r = rff.transform(Ztr)\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    C=LOGIT_C,\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=SEED\n",
    ").fit(Ztr_r, y_tr)\n",
    "\n",
    "# ---------- Validate (AUC + Brier on PROBABILITIES for Depression_{t+1}) ----------\n",
    "Zva   = scaler.transform(X_va)\n",
    "Zva_r = rff.transform(Zva)\n",
    "p_va  = clf.predict_proba(Zva_r)[:, 1]  # P(Depression_next = 1)\n",
    "\n",
    "auc   = roc_auc_score(y_va, p_va)\n",
    "brier = brier_score_loss(y_va, p_va)\n",
    "\n",
    "print(\"\\n=== Validation performance (predicting next-year Depression) ===\")\n",
    "print(f\"AUC   : {auc:.6f}\")\n",
    "print(f\"Brier : {brier:.6f}\")\n",
    "\n",
    "# ---------- Save validation probabilities ----------\n",
    "val_out = val_df.copy()\n",
    "# This is: P(Depression in Year+1 | features at Year)\n",
    "val_out[\"Depression_prob_next\"] = p_va\n",
    "\n",
    "val_out.to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nSaved validation probabilities to '{OUT_CSV}'.\")\n",
    "print(\"Column added: 'Depression_prob_next' (P(Depression in next year = 1)).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07efe369-0dc5-4090-8fe0-462dba913659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T01:41:02.426736Z",
     "iopub.status.busy": "2025-11-20T01:41:02.426422Z",
     "iopub.status.idle": "2025-11-20T01:41:03.242108Z",
     "shell.execute_reply": "2025-11-20T01:41:03.239655Z",
     "shell.execute_reply.started": "2025-11-20T01:41:02.426704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows (with next-year labels): 1021\n",
      "Forecast rows (2025 features -> 2026 prob): 25\n",
      "\n",
      "Saved probabilities to 'ForecastML3_with_probs_next.csv' (column: Depression_prob_2026).\n"
     ]
    }
   ],
   "source": [
    "# train_predict_depression_rff_next.py\n",
    "# Train on Train2ML.csv, using year t features to predict Depression in year t+1.\n",
    "# Then score ForecastML3.csv (2025 features) as 2026 depression probabilities.\n",
    "# Model: Standardize -> RFF (RBF) -> Logistic Regression (L2).\n",
    "# Target: Depression_next (Depression in t+1) in TRAIN only.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ---------- Config ----------\n",
    "TRAIN_CSV = \"Train2ML.csv\"\n",
    "VAL_CSV   = \"ForecastML3.csv\"   # 2025 rows; we will predict 2026 probs\n",
    "\n",
    "RFF_GAMMA = 0.2      # RBF width\n",
    "RFF_DIM   = 3000     # number of random Fourier features\n",
    "LOGIT_C   = 20.0     # inverse of L2 strength (larger C = weaker L2)\n",
    "SEED      = 42\n",
    "\n",
    "LABEL_COL = \"Depression_next\"   # we will create this from 'Depression' in TRAIN\n",
    "\n",
    "# Features (same as before, without \"Cons/GDP\")\n",
    "FEATURES = [\n",
    "    # Circulation\n",
    "    \"M0/GDP\",\"M1/GDP\",\"M0/M1\",\n",
    "    # Creation\n",
    "    \"∆ Debt/GDP\",\"Debt Growth\",\"Invest/GDP\",\n",
    "    # Valuation\n",
    "    \"REER\",\"Inflation Rate\",\"ST Interest\",\"HPI\",\"Curve\",\n",
    "    # Efficiency\n",
    "    \"UR\",\"CreditSprd\",\"Nom GDPg\"\n",
    "]\n",
    "\n",
    "OUT_CSV = \"ForecastML3_with_probs_next.csv\"\n",
    "\n",
    "# ---------- Load ----------\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df   = pd.read_csv(VAL_CSV)\n",
    "\n",
    "# ---------- Build next-year labels in TRAIN (Depression_{t+1}) ----------\n",
    "# We assume Train2ML has at least: Year, Depression, and FEATURES.\n",
    "# If you have Country, we use (Country, Year) to define \"next year within country\".\n",
    "\n",
    "if \"Country\" in train_df.columns and \"Year\" in train_df.columns:\n",
    "    train_df = train_df.sort_values([\"Country\", \"Year\"])\n",
    "    train_df[LABEL_COL] = train_df.groupby(\"Country\")[\"Depression\"].shift(-1)\n",
    "elif \"Year\" in train_df.columns:\n",
    "    train_df = train_df.sort_values(\"Year\")\n",
    "    train_df[LABEL_COL] = train_df[\"Depression\"].shift(-1)\n",
    "else:\n",
    "    raise ValueError(\"TRAIN_CSV must have at least a 'Year' column to build next-year labels.\")\n",
    "\n",
    "# Keep only rows with full features AND a defined next-year label\n",
    "train_df = train_df.dropna(subset=FEATURES + [LABEL_COL]).copy()\n",
    "\n",
    "# ---------- Design matrices ----------\n",
    "X_tr = train_df[FEATURES].values                 # features at year t\n",
    "y_tr = train_df[LABEL_COL].astype(int).values    # Depression at year t+1\n",
    "\n",
    "# For forecast file, we just need features at year t (2025); no label needed\n",
    "val_df = val_df.dropna(subset=FEATURES).copy()\n",
    "X_va   = val_df[FEATURES].values\n",
    "\n",
    "print(f\"Train rows (with next-year labels): {X_tr.shape[0]}\")\n",
    "print(f\"Forecast rows (2025 features -> 2026 prob): {X_va.shape[0]}\")\n",
    "\n",
    "# ---------- Standardize -> RFF -> Logistic ----------\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "Ztr    = scaler.transform(X_tr)\n",
    "\n",
    "rff = RBFSampler(\n",
    "    gamma=RFF_GAMMA,\n",
    "    n_components=RFF_DIM,\n",
    "    random_state=SEED\n",
    ").fit(Ztr)\n",
    "\n",
    "Ztr_r = rff.transform(Ztr)\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    C=LOGIT_C,\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=SEED\n",
    ").fit(Ztr_r, y_tr)\n",
    "\n",
    "# ---------- Predict Forecast (as 2026 probabilities from 2025 features) ----------\n",
    "Zva   = scaler.transform(X_va)\n",
    "Zva_r = rff.transform(Zva)\n",
    "p_va  = clf.predict_proba(Zva_r)[:, 1]  # P(Depression_next = 1 | features at 2025)\n",
    "\n",
    "# ---------- Save ----------\n",
    "val_out = val_df.copy()\n",
    "val_out[\"Depression_prob_2026\"] = p_va  # probability of Depression in 2026\n",
    "\n",
    "val_out.to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nSaved probabilities to '{OUT_CSV}' (column: Depression_prob_2026).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1dbf34-1f62-4c7b-ae07-a0dda19e1cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
